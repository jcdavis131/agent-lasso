# Agent Lasso â€“ Configure, Play, Benchmark.

*Transform complex data into actionable insights*

Agent Lasso is a lightweight AI platform that lets you assemble specialised "agents", run them through real-time chats, and benchmark their performance â€“ all from a single web interface powered by FastAPI + Tailwind.

---
## ğŸ¯ Why Agent Lasso?
* âœ… **Zero-Friction Deployment** â€“ no cloud accounts or databases required. Runs locally, deploys to Vercel in one click.
* âœ… **Adaptive Intelligence** â€“ plug-and-play tools, configurable LLM back-ends and auto-optimising agent templates.
* âœ… **Privacy by Design** â€“ everything is processed on your machine unless you opt-in to external APIs.
* âœ… **Intuitive Mastery** â€“ visual interface, live progress events and persistent conversation threads.
* âœ… **Scalable Architecture** â€“ GraphRAG-ready knowledge graph layer plus Neo4j / JSON fallback.

---
## ğŸš€ Quick Start
1. Create a virtual environment (optional but recommended)
```bash
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
```
2. Install the dependencies
```bash
pip install -r requirements.txt
```
3. (Optional) add API keys & secrets
Create a `secrets.txt` file in the project root. Any `KEY=value` pair in this file is automatically loaded at runtime:
```text
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=...
MISTRAL_API_KEY=...
GROQ_API_KEY=...
NEO4J_PASSWORD=...
```
4. Start the development server (hot-reload)
```bash
uvicorn agent_setup_landing:app --reload
```
Open http://127.0.0.1:8000 in your browser âœ the full glass-morphic UI will load.

> In production you can either:
> â€¢ `uvicorn agent_setup_landing:app --host 0.0.0.0 --port 8000` on your own box, or
> â€¢ **Deploy to Vercel** â€“ the provided `vercel.json` is pre-configured.

---
## ğŸ› ï¸ Available Tools
| Category | Tool | Description |
|----------|------|-------------|
| Core (always on) | `file_operations` | Read, write, append, delete files & list directories |
|  | `data_analysis` | Quick descriptive stats, correlations & basic visualisations for CSV / JSON |
|  | `current_time` | Returns the current date & time (temporal grounding) |
|  | `calculator` | Safe arithmetic expression evaluator |
| Search | `duckduckgo_search` | Privacy-respecting web search (no key) |
|  | `searx_search` | Search via your own or public SearXNG instance |
| Optional | `weather` | Local weather via OpenWeatherMap (uses `OPENWEATHER_API_KEY` if present, otherwise link fallback) |
|  | `arxiv_search` | Academic paper search through arXiv API |
| Interactive | `interactive_canvas` | Opens a collaborative canvas, lets the agent draw / clear shapes |

Retrieve the live tool objects in Python:
```python
from tools import get_tools
for t in get_tools():
    print(t.name, '-', t.description)
```

---
## ğŸŒ User Interface
* **FastAPI backend** â€“ JSON & SSE endpoints under `/api/*`.
* **Jinja-tailwind frontend** â€“ single-page app in `templates/index.html` with progressive enhancement.
* **Live agent stream** â€“ watch your agent think, use tools and refine answers step-by-step.
* **Persistent SQLite storage** â€“ conversations, agent configurations and benchmark scores live in `agent_log.db`.

---
## ğŸ§  GraphRAG Engine  
`graphrag_engine.py` provides a pluggable GraphRAG layer.
* **Neo4j mode** â€“ vector & graph indices inside Neo4j 5.x (requires server + credentials).
* **JSON fallback** â€“ zero-dependency in-memory graph for local testing.
* Sentence-Transformers embeddings with optional chunk filtering.

Configure via `config.GRAPHRAG_CONFIG` or override with environment variables.

---
## ğŸ§ª Benchmarking
The `/api/benchmark/*` endpoints let you execute pluggable test harnesses (see `benchmarks.py`).  Results are stored and a live leaderboard is available in the UI.

---
## âš™ï¸ Configuration Cheatsheet
| File | Purpose |
|------|---------|
| `secrets.txt` | **Recommended** place for keys & passwords (git-ignored) |
| `config.py` | Default model providers, embedding models, GraphRAG & tool settings |
| `database.py` | SQLite schema & helper functions |
| `vercel.json` | Zero-config deployment to Vercel Functions |

Most settings can also be overridden via standard environment variables.

---
## ğŸ“¦ Key Dependencies
```
langchain>=0.3.9
langchain-core>=0.3.21
fastapi>=0.109.0
uvicorn>=0.32.0
pandas>=2.0.0
sentence-transformers>=2.2.2
neo4j>=5.0.0  # optional, for full GraphRAG
```
See `requirements.txt` for the exhaustive list and pinned versions.

---
## ğŸ”§ Troubleshooting
* **DuckDuckGo search not working** âœ `pip install --upgrade duckduckgo-search`
* **Neo4j connection refused** âœ ensure Neo4j is running (`docker run -p 7687:7687 neo4j:5`), then set `NEO4J_PASSWORD`.
* **Port already in use** âœ change the port: `uvicorn agent_setup_landing:app --port 9000 --reload`.

---
## ğŸ¤ Contributing
1. Fork the repo & create a feature branch.
2. Run the unit tests & `black .`.
3. Open a PR â€“ please describe the tool / feature you added and include benchmark results if relevant.

---
## ğŸ“„ License
MIT â€“ do what you want, just give credit.